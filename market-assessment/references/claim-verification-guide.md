# Claim Verification Guide

Use this guide to systematically verify marketing claims made by the target company. Assess what's verifiable truth versus unverified or potentially misleading claims.

---

## Verification Framework

### Verification Status Taxonomy

| Symbol | Status | Definition |
|--------|--------|------------|
| ‚úÖ | **Verified** | Strong evidence confirms the claim (GitHub metrics, third-party validation, verifiable data) |
| ‚úì | **Likely True** | Circumstantial evidence supports the claim (credible sources, logical consistency) |
| ‚ö†Ô∏è | **Unverified** | Claim made but no evidence found to confirm or contradict |
| ‚ùå | **Contradicted** | Evidence suggests the claim is false or significantly misleading |
| üîç | **Needs Investigation** | Claim requires deeper research to verify |

### Evidence Hierarchy (Strongest ‚Üí Weakest)

1. **Verifiable Metrics** (‚úÖ)
   - GitHub stars, commits, contributors (public)
   - Open-source code (can inspect)
   - Public financial filings (for public companies)
   - Third-party benchmarks and tests
   - Academic papers and peer review
   - Court/legal documents

2. **Third-Party Validation** (‚úÖ or ‚úì)
   - Independent reviews and analysis
   - Customer testimonials (verified customers)
   - Industry analyst reports (Gartner, Forrester)
   - News articles from credible outlets
   - Conference presentations (non-promotional)

3. **Company-Provided Evidence** (‚úì)
   - Case studies with named customers
   - White papers with methodology
   - Technical documentation
   - Blog posts with data
   - Product demos and screenshots

4. **Company Claims** (‚ö†Ô∏è unless supported)
   - Marketing website copy
   - Press releases
   - Pitch decks
   - Sales materials
   - Social media posts

5. **Hearsay** (‚ö†Ô∏è)
   - Anonymous testimonials
   - Unattributed quotes
   - Rumors or speculation
   - Unverified forum posts

---

## Claim Categories & Verification Strategies

### 1. Technical Performance Claims

**Common Claims:**
- "Fastest inference engine"
- "10x smaller than alternatives"
- "Zero dependencies"
- "Best accuracy in class"
- "Sub-millisecond latency"

**Verification Strategy:**
- Check GitHub for benchmarks and reproducible tests
- Look for third-party benchmark comparisons
- Review technical documentation for specifications
- Test the product if possible (hands-on verification)
- Compare against competitor specs
- Check for standardized benchmark results (MLPerf, etc.)

**Red Flags:**
- Vague claims without metrics ("blazing fast")
- Cherry-picked benchmarks
- Uncommon or custom benchmarks
- No methodology disclosed
- Comparing against outdated alternatives

---

### 2. Market Position Claims

**Common Claims:**
- "Industry leader"
- "Most popular solution"
- "Trusted by thousands of companies"
- "Fastest-growing platform"
- "#1 choice for developers"

**Verification Strategy:**
- Check third-party market research (IDC, Gartner)
- Verify GitHub stars, downloads, package manager stats
- Search for industry reports and rankings
- Check analyst recognition (Magic Quadrant, Wave, etc.)
- Verify customer count through LinkedIn, job postings
- Check social media following and engagement

**Red Flags:**
- Self-proclaimed without citations
- Vague qualifiers ("one of the leading")
- Limited market definition to make claim true
- No time frame specified
- No comparison basis specified

---

### 3. Customer/Traction Claims

**Common Claims:**
- "Used by Fortune 500 companies"
- "Millions of developers use our tool"
- "Trusted by [specific company logos]"
- "X% customer satisfaction"
- "Y% growth rate"

**Verification Strategy:**
- Verify specific customer logos (case studies, customer websites, news)
- Check company LinkedIn for employee mentions of tool
- Search news for customer announcements
- Verify download stats from package managers
- Check GitHub repository clones/stars
- Look for customer testimonials with names/titles
- Third-party review sites (G2, Capterra, TrustRadius)

**Red Flags:**
- Logo wall without customer quotes or case studies
- Vague "millions of users" without source
- Free tier users counted as "customers"
- Anonymous testimonials
- Unverifiable statistics
- Outdated metrics presented as current

---

### 4. Funding & Financial Claims

**Common Claims:**
- "Backed by [VC firm]"
- "Raised $X million"
- "Valued at $Y"
- "Profitable"
- "Growing X% year-over-year"

**Verification Strategy:**
- Cross-check with Crunchbase, PitchBook
- Search news for funding announcements
- Check VC firm portfolio pages
- For public companies: review SEC filings
- Look for founder/investor social media confirmations
- Search press releases and news archives

**Red Flags:**
- Vague about amount or timing
- Claiming "backed by" without actual investment
- Misrepresenting investor tier
- Outdated funding info presented as recent
- Conflating grants with equity funding

---

### 5. Product Capability Claims

**Common Claims:**
- "Supports all major platforms"
- "Enterprise-ready"
- "Production-grade"
- "Scales to billions of requests"
- "99.99% uptime"
- "SOC2/ISO certified"

**Verification Strategy:**
- Check documentation for actual platform support
- Review GitHub issues for scale/stability problems
- Look for SLA documentation
- Verify security certifications (usually listed with cert numbers)
- Check status page for historical uptime
- Look for enterprise features in docs
- Check customer case studies for scale examples

**Red Flags:**
- Vague capability claims
- "Enterprise-ready" without specifics
- Claims without documentation
- No evidence in codebase
- Community reports contradicting claims

---

### 6. Team & Credentials Claims

**Common Claims:**
- "Built by former [FAANG] engineers"
- "Founded by [credential/achievement]"
- "Team from [prestigious institution]"
- "X years of combined experience"
- "Led [project] at [company]"

**Verification Strategy:**
- Check LinkedIn profiles
- Verify employment history
- Check GitHub profiles for contribution history
- Verify academic credentials
- Cross-reference with news articles, interviews
- Check previous projects/contributions

**Red Flags:**
- Vague affiliations without names
- Overstating roles (intern ‚Üí "worked at Google")
- Unverifiable credentials
- Using outdated affiliations

---

### 7. Differentiation Claims

**Common Claims:**
- "Only solution that [does X]"
- "First to market with [feature]"
- "Unlike competitors, we..."
- "Unique approach to [problem]"
- "Patent-pending technology"

**Verification Strategy:**
- Research competitors thoroughly to verify "only" claims
- Check patent databases (USPTO, EPO)
- Review competitor documentation for similar features
- Look at historical product releases for "first to market"
- Analyze actual product differences

**Red Flags:**
- Narrow definition to make claim technically true
- Ignoring obvious competitors
- Claiming uniqueness on commodity features
- "Patent-pending" without specificity

---

## Verification Workflow

### Step 1: Extract All Claims

Review all company materials and extract distinct claims:
- Marketing website
- Product pages
- About/team pages
- Press releases
- Pitch decks
- Social media
- Documentation

Create a comprehensive list of claims to verify.

### Step 2: Categorize Claims

Group claims by category:
- Technical performance
- Market position
- Customer/traction
- Funding/financial
- Product capabilities
- Team/credentials
- Differentiation

### Step 3: Prioritize Claims

Focus on claims that are:
- **Business-critical:** Claims central to value proposition
- **Differentiating:** Claims that distinguish from competitors
- **Quantitative:** Specific numbers and metrics
- **Suspicious:** Claims that seem too good or vague

### Step 4: Research Each Claim

For each priority claim:
1. Identify what evidence would verify it
2. Search for that evidence systematically
3. Document findings
4. Assign verification status
5. Note confidence level

### Step 5: Document Results

Create a structured claim verification report (template below).

---

## Claim Verification Report Template

### Company: [Target Company Name]

**Analysis Date:** [YYYY-MM-DD]
**Analyst:** [Name]

---

### Summary Statistics

- **Total Claims Analyzed:** [#]
- **Verified (‚úÖ):** [#] ([%]%)
- **Likely True (‚úì):** [#] ([%]%)
- **Unverified (‚ö†Ô∏è):** [#] ([%]%)
- **Contradicted (‚ùå):** [#] ([%]%)
- **Needs Investigation (üîç):** [#] ([%]%)

**Overall Credibility Assessment:** [High / Medium / Low]

---

### Detailed Claim Analysis

#### Technical Performance Claims

| Claim | Source | Status | Evidence | Confidence |
|-------|--------|--------|----------|------------|
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |

**Category Assessment:** [Are technical claims generally verified or not?]

#### Market Position Claims

| Claim | Source | Status | Evidence | Confidence |
|-------|--------|--------|----------|------------|
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |

**Category Assessment:** [Are market claims generally verified or not?]

#### Customer/Traction Claims

| Claim | Source | Status | Evidence | Confidence |
|-------|--------|--------|----------|------------|
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |

**Category Assessment:** [Are traction claims generally verified or not?]

#### Product Capability Claims

| Claim | Source | Status | Evidence | Confidence |
|-------|--------|--------|----------|------------|
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |
| [Claim text] | [Where found] | ‚úÖ/‚úì/‚ö†Ô∏è/‚ùå | [Evidence description] | High/Med/Low |

**Category Assessment:** [Are capability claims generally verified or not?]

[Continue for other categories...]

---

### Red Flags Identified

**Critical Concerns:**
1. [Claim that's contradicted or highly misleading]
   - **Why it's concerning:** [Explanation]
   - **Impact:** [Business/credibility impact]

2. [Claim that's contradicted or highly misleading]
   - **Why it's concerning:** [Explanation]
   - **Impact:** [Business/credibility impact]

**Moderate Concerns:**
1. [Claim that's unverified or vague]
   - **Why it matters:** [Explanation]

[Add more as needed]

---

### Well-Supported Claims

**Strengths (Verified Claims):**
1. [Claim that checks out with strong evidence]
   - **Evidence:** [What confirms this]
   - **Significance:** [Why this matters]

2. [Claim that checks out with strong evidence]
   - **Evidence:** [What confirms this]
   - **Significance:** [Why this matters]

[Add more as needed]

---

### Key Takeaways

**Overall Credibility Assessment:**
[2-3 paragraphs assessing whether the company makes credible, verifiable claims or tends toward unverifiable/misleading claims. Consider:]
- Pattern of verifiable vs unverifiable claims
- Severity of any misleading claims
- Whether exaggerations are minor or material
- Transparency in providing evidence
- Comparison to industry norms

**Most Concerning Findings:**
1. [Finding 1]
2. [Finding 2]
3. [Finding 3]

**Most Credible Aspects:**
1. [Aspect 1]
2. [Aspect 2]
3. [Aspect 3]

**Recommendations:**
- [Recommendation for further investigation]
- [Recommendation for risk assessment]
- [Recommendation for due diligence]

---

## Common Verification Pitfalls to Avoid

1. **Confirmation Bias:** Looking only for evidence that supports claims, not contradicting evidence
2. **Trust Without Verification:** Accepting company claims at face value
3. **Outdated Information:** Using old data to verify current claims
4. **Correlation ‚â† Causation:** Mistaking correlations for proof of claims
5. **Cherry-Picked Evidence:** Finding one piece of supporting evidence and stopping
6. **Scope Limitation Errors:** Missing that claims are technically true but misleadingly narrow
7. **Authority Bias:** Overweighting claims because of who makes them
8. **Anchoring:** Being influenced by initial positive/negative impressions

---

## Verification Resources

### Useful Tools & Databases:
- **GitHub:** Repository metrics, code inspection, issue tracking
- **Crunchbase/PitchBook:** Funding data
- **LinkedIn:** Team verification, company size
- **Wayback Machine:** Historical website claims
- **Google Patents:** Patent verification
- **SEC EDGAR:** Public company filings (if applicable)
- **Domain Authority Tools:** Website traffic estimates
- **Package Managers:** Download stats (npm, PyPI, etc.)
- **Social Media:** Follower counts, engagement
- **Review Sites:** G2, Capterra, TrustRadius

### Search Strategies:
- `"[company name]" [claim]` - Direct search
- `[company name] -site:[company].com` - Exclude company site
- `[company name] review` - Find third-party assessments
- `[company name] vs [competitor]` - Comparative analysis
- `[founder name] [claim]` - Verify founder credentials
- `site:github.com [company/product]` - GitHub mentions
- `site:news.ycombinator.com [company]` - HN discussions
